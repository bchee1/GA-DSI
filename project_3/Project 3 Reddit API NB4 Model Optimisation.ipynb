{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Natural Language Processing and Classification\n",
    "\n",
    "Benjamin Chee, DSI-SG-17\n",
    "\n",
    "Classifying posts from r/xboxone and r/PS5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Model Optimisation\n",
    "\n",
    "This notebook contains code used to classify with models using our prepared data.\n",
    "\n",
    "The following were used:\n",
    "- Multinomial Naive Bayes\n",
    "- K-Nearest Neighbors\n",
    "- Logistic Regression Classifier\n",
    "- Random Forest\n",
    "\n",
    "GridSearch was then used to optimise each model, and and evaluation was done\n",
    "\n",
    "Contents:\n",
    "- GridSearch - CountVectorizer\n",
    "- GridSearch - TF-IDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# general scikitlearn imports\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#NLP\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise date time\n",
    "date_run = datetime.datetime.now()\n",
    "date= date_run.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reading output from notebook 1\n",
    "df_pre=pd.read_csv('./csv/df_pre_2020-10-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pre[['post_st','post_lm']]\n",
    "y = df_pre['from_ps5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_st</th>\n",
       "      <th>post_lm</th>\n",
       "      <th>from_ps5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech weekli xbox one tech support thi is the t...</td>\n",
       "      <td>tech weekly xbox one tech support this is the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gta iv one of my fav game ever nearli a lock  ...</td>\n",
       "      <td>gta iv one of my fav game ever nearly a locked...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>more seri x load time comparison</td>\n",
       "      <td>more series x load time comparison</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digit foundri xbox seri x backward compat test...</td>\n",
       "      <td>digital foundry xbox series x backwards compat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you rememb when thi pictur blew our mind</td>\n",
       "      <td>do you remember when this picture blew our mind</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             post_st  \\\n",
       "0  tech weekli xbox one tech support thi is the t...   \n",
       "1  gta iv one of my fav game ever nearli a lock  ...   \n",
       "2                   more seri x load time comparison   \n",
       "3  digit foundri xbox seri x backward compat test...   \n",
       "4        do you rememb when thi pictur blew our mind   \n",
       "\n",
       "                                             post_lm  from_ps5  \n",
       "0  tech weekly xbox one tech support this is the ...         0  \n",
       "1  gta iv one of my fav game ever nearly a locked...         0  \n",
       "2                 more series x load time comparison         0  \n",
       "3  digital foundry xbox series x backwards compat...         0  \n",
       "4    do you remember when this picture blew our mind         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1021"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1021"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorised Multinomial Naive BayesÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_runs = pd.DataFrame(columns=['train_accuracy','test_accuracy','bp','tn','fp','fn','tp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [train_accuracy, test_accuracy, bp, tn, fp, fn, tp]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for GridSearch using Pipeline, formatted to call named estimators\n",
    "mnb_params = {'mnb__alpha':np.arange(1.04,1.06,0.005), 'cv__max_features':np.arange(3450,3550,20)}\n",
    "\n",
    "# steps defining pipeline sequence and fixed parameters for GridSearch\n",
    "mnb_steps = [('cv',CountVectorizer(stop_words='english', ngram_range=(1,1))),\n",
    "            ('mnb',MultinomialNB())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(mnb_steps) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_post = X_train['post_lm']\n",
    "X_test_post = X_test['post_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9618021547502449\n",
      "Test Accuracy:  0.906158357771261\n",
      "BP:  {'cv__max_features': 3490, 'mnb__alpha': 1.0499999999999998}\n",
      "True Negatives: 191\n",
      "True Positives: 21\n",
      "True Negatives: 11\n",
      "True Positives: 118 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_post_results = {} # empty dict to store results\n",
    "\n",
    "grid = GridSearchCV(pipe, mnb_params, cv=5) # optimize GridSearch hyperparameters on `cv=5` cross validation runs\n",
    "grid.fit(X_train_post, y_train) # fit to our training data\n",
    "\n",
    "print('Train Accuracy: ',grid.score(X_train_post, y_train))\n",
    "mnb_post_results['train_accuracy'] = grid.score(X_train_post, y_train) # print/store training accuracy\n",
    "\n",
    "print('Test Accuracy: ',grid.score(X_test_post, y_test))\n",
    "mnb_post_results['test_accuracy'] = grid.score(X_test_post, y_test) # print/store test accuracy\n",
    "\n",
    "print('BP: ',grid.best_params_)\n",
    "mnb_post_results['bp'] = grid.best_params_ # print/store best parameters\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_post)).ravel() # inspect counted results in matrix\n",
    "print(f'True Negatives: {tn}')\n",
    "mnb_post_results['tn'] = tn\n",
    "\n",
    "print(f'True Positives: {fp}')\n",
    "mnb_post_results['fp'] = fp\n",
    "\n",
    "print(f'True Negatives: {fn}')\n",
    "mnb_post_results['fn'] = fn\n",
    "\n",
    "print(f'True Positives: {tp}', '\\n')\n",
    "mnb_post_results['tp'] = tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_runs = mnb_runs.append(mnb_post_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.962782</td>\n",
       "      <td>0.897361</td>\n",
       "      <td>{'cv__max_features': 3500, 'mnb__alpha': 1.2}</td>\n",
       "      <td>190</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.965720</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>{'cv__max_features': 3800, 'mnb__alpha': 1.1}</td>\n",
       "      <td>193</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.961802</td>\n",
       "      <td>0.906158</td>\n",
       "      <td>{'cv__max_features': 3500, 'mnb__alpha': 1.05}</td>\n",
       "      <td>191</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.961802</td>\n",
       "      <td>0.906158</td>\n",
       "      <td>{'cv__max_features': 3490, 'mnb__alpha': 1.049...</td>\n",
       "      <td>191</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.962782       0.897361   \n",
       "1        0.965720       0.909091   \n",
       "2        0.961802       0.906158   \n",
       "3        0.961802       0.906158   \n",
       "\n",
       "                                                  bp   tn  fp  fn   tp  \n",
       "0      {'cv__max_features': 3500, 'mnb__alpha': 1.2}  190  22  13  116  \n",
       "1      {'cv__max_features': 3800, 'mnb__alpha': 1.1}  193  19  12  117  \n",
       "2     {'cv__max_features': 3500, 'mnb__alpha': 1.05}  191  21  11  118  \n",
       "3  {'cv__max_features': 3490, 'mnb__alpha': 1.049...  191  21  11  118  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_runs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_runs = pd.DataFrame(columns=['train_accuracy','test_accuracy','bp','tn','fp','fn','tp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [train_accuracy, test_accuracy, bp, tn, fp, fn, tp]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\"rf__n_estimators\":np.arange(92,96,1), \"rf__max_depth\": np.arange(7,9,1), \n",
    "             \"tf__max_features\":[None,35000,40000,45000]}\n",
    "rf_steps = [('tf',TfidfVectorizer(stop_words='english', ngram_range=(1,1))),\n",
    "             ('rf',RandomForestClassifier(random_state=42))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(rf_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.7806072477962782\n",
      "Test Accuracy:  0.7390029325513197\n",
      "BP:  {'rf__max_depth': 8, 'rf__n_estimators': 93, 'tf__max_features': None}\n",
      "True Negatives: 212\n",
      "False Positives: 0\n",
      "False Negatives: 89\n",
      "True Positives: 40 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_post_results = {}\n",
    "\n",
    "grid = GridSearchCV(pipe, rf_params, cv=5)\n",
    "grid.fit(X_train_post, y_train)\n",
    "\n",
    "print('Train Accuracy: ',grid.score(X_train_post, y_train))\n",
    "rf_post_results['train_accuracy'] = grid.score(X_train_post, y_train)\n",
    "\n",
    "print('Test Accuracy: ',grid.score(X_test_post, y_test))\n",
    "rf_post_results['test_accuracy'] = grid.score(X_test_post, y_test)\n",
    "\n",
    "print('BP: ',grid.best_params_)\n",
    "rf_post_results['bp'] = grid.best_params_\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_post)).ravel()\n",
    "print(f'True Negatives: {tn}')\n",
    "rf_post_results['tn'] = tn\n",
    "\n",
    "print(f'False Positives: {fp}')\n",
    "rf_post_results['fp'] = fp\n",
    "\n",
    "print(f'False Negatives: {fn}')\n",
    "rf_post_results['fn'] = fn\n",
    "\n",
    "print(f'True Positives: {tp}', '\\n')\n",
    "rf_post_results['tp'] = tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_runs = rf_runs.append(rf_post_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.780607</td>\n",
       "      <td>0.739003</td>\n",
       "      <td>{'rf__max_depth': 8, 'rf__n_estimators': 93, '...</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.780607       0.739003   \n",
       "\n",
       "                                                  bp   tn fp  fn  tp  \n",
       "0  {'rf__max_depth': 8, 'rf__n_estimators': 93, '...  212  0  89  40  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorised K Nearest Neighbours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_runs = pd.DataFrame(columns=['train_accuracy','test_accuracy','bp','tn','fp','fn','tp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {'knn__n_neighbors':np.arange(2,5,1)}\n",
    "knn_steps = [('cv',CountVectorizer(stop_words='english', ngram_range=(1,1))),\n",
    "            ('sc',StandardScaler(with_mean=False)),\n",
    "            ('knn',KNeighborsClassifier())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.791380999020568\n",
      "Test Accuracy:  0.6744868035190615\n",
      "BP:  {'knn__n_neighbors': 3}\n",
      "True Negatives: 204\n",
      "False Positives: 8\n",
      "False Negatives: 103\n",
      "True Positives: 26 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(knn_steps)\n",
    "knn_post_results = {}\n",
    "\n",
    "grid = GridSearchCV(pipe, knn_params, cv=3)\n",
    "grid.fit(X_train_post, y_train)\n",
    "\n",
    "print('Train Accuracy: ',grid.score(X_train_post, y_train))\n",
    "knn_post_results['train_accuracy'] = grid.score(X_train_post, y_train)\n",
    "\n",
    "print('Test Accuracy: ',grid.score(X_test_post, y_test))\n",
    "knn_post_results['test_accuracy'] = grid.score(X_test_post, y_test)\n",
    "\n",
    "print('BP: ',grid.best_params_)\n",
    "knn_post_results['bp'] = grid.best_params_\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_post)).ravel()\n",
    "print(f'True Negatives: {tn}')\n",
    "knn_post_results['tn'] = tn\n",
    "\n",
    "print(f'False Positives: {fp}')\n",
    "knn_post_results['fp'] = fp\n",
    "\n",
    "print(f'False Negatives: {fn}')\n",
    "knn_post_results['fn'] = fn\n",
    "\n",
    "print(f'True Positives: {tp}', '\\n')\n",
    "knn_post_results['tp'] = tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_runs = knn_runs.append(knn_post_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.791381</td>\n",
       "      <td>0.674487</td>\n",
       "      <td>{'knn__n_neighbors': 3}</td>\n",
       "      <td>204</td>\n",
       "      <td>8</td>\n",
       "      <td>103</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy                       bp   tn fp   fn  tp\n",
       "0        0.791381       0.674487  {'knn__n_neighbors': 3}  204  8  103  26"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorised Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_runs = pd.DataFrame(columns=['train_accuracy','test_accuracy','bp','tn','fp','fn','tp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\"lr__penalty\":['l1'], \"lr__C\": [1.44,1.45,1.46,1.47,1.43],\n",
    "             \"lr__tol\":[.001], \"cv__max_features\":[17000,16750,17250]}\n",
    "lr_steps = [('cv',CountVectorizer(stop_words='english', ngram_range=(1,1))),\n",
    "            ('sc',StandardScaler(with_mean=False)),\n",
    "            ('lr',LogisticRegression(solver='saga',random_state=42,max_iter=9999,n_jobs=-1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9980411361410382\n",
      "Test Accuracy:  0.8563049853372434\n",
      "BP:  {'cv__max_features': 17000, 'lr__C': 1.44, 'lr__penalty': 'l1', 'lr__tol': 0.001}\n",
      "True Negatives: 196\n",
      "False Positives: 16\n",
      "False Negatives: 33\n",
      "True Positives: 96 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(lr_steps)\n",
    "lr_post_results = {}\n",
    "\n",
    "grid = GridSearchCV(pipe, lr_params, cv=3)\n",
    "grid.fit(X_train_post, y_train)\n",
    "\n",
    "print('Train Accuracy: ',grid.score(X_train_post, y_train))\n",
    "lr_post_results['train_accuracy'] = grid.score(X_train_post, y_train)\n",
    "\n",
    "print('Test Accuracy: ',grid.score(X_test_post, y_test))\n",
    "lr_post_results['test_accuracy'] = grid.score(X_test_post, y_test)\n",
    "\n",
    "print('BP: ',grid.best_params_)\n",
    "lr_post_results['bp'] = grid.best_params_\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_post)).ravel()\n",
    "print(f'True Negatives: {tn}')\n",
    "lr_post_results['tn'] = tn\n",
    "\n",
    "print(f'False Positives: {fp}')\n",
    "lr_post_results['fp'] = fp\n",
    "\n",
    "print(f'False Negatives: {fn}')\n",
    "lr_post_results['fn'] = fn\n",
    "\n",
    "print(f'True Positives: {tp}', '\\n')\n",
    "lr_post_results['tp'] = tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_runs = lr_runs.append(lr_post_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>bp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998041</td>\n",
       "      <td>0.856305</td>\n",
       "      <td>{'cv__max_features': 17000, 'lr__C': 1.44, 'lr...</td>\n",
       "      <td>196</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_accuracy  test_accuracy  \\\n",
       "0        0.998041       0.856305   \n",
       "\n",
       "                                                  bp   tn  fp  fn  tp  \n",
       "0  {'cv__max_features': 17000, 'lr__C': 1.44, 'lr...  196  16  33  96  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Model Features\n",
    "\n",
    "### Model 1: Multinomial Naive-Bayes\n",
    "\n",
    "- Lemmatizer\n",
    "- CountVectorizer\n",
    "    - stop_words='english'\n",
    "    - ngram_range=(1,1)\n",
    "- GridSearch\n",
    "    - cv__max_features=3490\n",
    "    - mnb__alpha=1.05\n",
    "\n",
    "### Model 2: Random Forest\n",
    "\n",
    "- Lemmatizer\n",
    "- CountVectorizer\n",
    "    - stop_words='english'\n",
    "    - ngram_range=(1,1)\n",
    "- GridSearch\n",
    "    - tf__max_features=None\n",
    "    - rf__criterion='gini'\n",
    "    - rf__n_estimators=93\n",
    "    - rf__max_depth=8\n",
    "\n",
    "### Model 3: KNN\n",
    "\n",
    "- Lemmatizer\n",
    "- CountVectorizer\n",
    "    - stop_words='english'\n",
    "    - ngram_range=(1,1)\n",
    "- GridSearch\n",
    "    - cv__max_features=None\n",
    "    - n_neighbours=3\n",
    "\n",
    "### Model 4: Logistic Regression\n",
    "\n",
    "- Lemmatizer\n",
    "- CountVectorizer\n",
    "    - stop_words='english'\n",
    "    - ngram_range=(1,1)\n",
    "- GridSearch\n",
    "    - cv__max_features=1700\n",
    "    - lr__C=1.44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our model hyperparameters optimized through GridSearch, we build each desired model pipeline.\n",
    "\n",
    "## Model 1 Optimized: Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_steps = [('m1_cv',CountVectorizer(stop_words='english', ngram_range=(1,1), max_features=3490)),\n",
    "           ('m1_mnb',MultinomialNB(alpha=1.05))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('m1_cv',\n",
       "                 CountVectorizer(max_features=3490, stop_words='english')),\n",
       "                ('m1_mnb', MultinomialNB(alpha=1.05))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_1 = Pipeline(m1_steps)\n",
    "pipe_1.fit(X_train.post_lm, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = [i[1] for i in pipe_1.predict_proba(X_test.post_lm)]\n",
    "\n",
    "pred_df = pd.DataFrame({'true_values': y_test,\n",
    "                        'pred_probs':pred_proba})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9749524645312271"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(pred_df['true_values'], pred_df['pred_probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.906158357771261"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_1.score(X_test.post_lm, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 191\n",
      "False Positives: 21\n",
      "False Negatives: 11\n",
      "True Positives: 118\n",
      "\n",
      "Accuracy:  0.906158357771261\n",
      "Sensitivity:  0.9147286821705426\n",
      "Specificity:  0.9009433962264151\n",
      "Precision:  0.8489208633093526\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, pipe_1.predict(X_test.post_lm)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 Optimized: TF IDF Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_steps = [('m2_tf',TfidfVectorizer(stop_words='english', ngram_range=(1,1))),\n",
    "           ('m2_rf',RandomForestClassifier(criterion='gini', n_estimators=93, max_depth=8))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('m2_tf', TfidfVectorizer(stop_words='english')),\n",
       "                ('m2_rf',\n",
       "                 RandomForestClassifier(max_depth=8, n_estimators=93))])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_2 = Pipeline(m2_steps)\n",
    "pipe_2.fit(X_train.post_lm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = [i[1] for i in pipe_2.predict_proba(X_test.post_lm)]\n",
    "\n",
    "pred_df = pd.DataFrame({'true_values': y_test,\n",
    "                        'pred_probs':pred_proba})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9694676027497441"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(pred_df['true_values'], pred_df['pred_probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8064516129032258"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_2.score(X_test.post_lm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 212\n",
      "False Positives: 0\n",
      "False Negatives: 66\n",
      "True Positives: 63\n",
      "\n",
      "Accuracy:  0.8064516129032258\n",
      "Sensitivity:  0.4883720930232558\n",
      "Specificity:  1.0\n",
      "Precision:  1.0\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, pipe_2.predict(X_test.post_lm)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 Optimized: K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_steps = [('m3_cv',CountVectorizer(stop_words='english', ngram_range=(1,1), max_features=None)),\n",
    "            ('m3_sc',StandardScaler(with_mean=False)),\n",
    "            ('m3_knn',KNeighborsClassifier(n_neighbors=3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('m3_cv', CountVectorizer(stop_words='english')),\n",
       "                ('m3_sc', StandardScaler(with_mean=False)),\n",
       "                ('m3_knn', KNeighborsClassifier(n_neighbors=3))])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_3 = Pipeline(m3_steps)\n",
    "pipe_3.fit(X_train.post_lm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = [i[1] for i in pipe_3.predict_proba(X_test.post_lm)]\n",
    "\n",
    "pred_df = pd.DataFrame({'true_values': y_test,\n",
    "                        'pred_probs':pred_proba})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7144032470381747"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(pred_df['true_values'], pred_df['pred_probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6744868035190615"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_3.score(X_test.post_lm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 204\n",
      "False Positives: 8\n",
      "False Negatives: 103\n",
      "True Positives: 26\n",
      "\n",
      "Accuracy:  0.6744868035190615\n",
      "Sensitivity:  0.20155038759689922\n",
      "Specificity:  0.9622641509433962\n",
      "Precision:  0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, pipe_3.predict(X_test.post_lm)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Model 4 Optimized: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_steps = [('m4_cv',CountVectorizer(stop_words='english', ngram_range=(1,1), max_features=1700)),\n",
    "            ('m4_sc',StandardScaler(with_mean=False)),\n",
    "            ('m4_lr',LogisticRegression(penalty='l1',solver='saga', C=1.44, tol=.001,max_iter=9999))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('m4_cv',\n",
       "                 CountVectorizer(max_features=1700, stop_words='english')),\n",
       "                ('m4_sc', StandardScaler(with_mean=False)),\n",
       "                ('m4_lr',\n",
       "                 LogisticRegression(C=1.44, max_iter=9999, penalty='l1',\n",
       "                                    solver='saga', tol=0.001))])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_4 = Pipeline(m4_steps)\n",
    "pipe_4.fit(X_train.post_lm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = [i[1] for i in pipe_4.predict_proba(X_test.post_lm)]\n",
    "\n",
    "pred_df = pd.DataFrame({'true_values': y_test,\n",
    "                        'pred_probs':pred_proba})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9323533713617084"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(pred_df['true_values'], pred_df['pred_probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709677419354839"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_4.score(X_test.post_lm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 193\n",
      "False Positives: 19\n",
      "False Negatives: 25\n",
      "True Positives: 104\n",
      "\n",
      "Accuracy:  0.8709677419354839\n",
      "Sensitivity:  0.8062015503875969\n",
      "Specificity:  0.910377358490566\n",
      "Precision:  0.8455284552845529\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, pipe_4.predict(X_test.post_lm)).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)\n",
    "\n",
    "print(\"\\nAccuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Model Features\n",
    "\n",
    "### Model 1: Multinomial Naive-Bayes\n",
    "\n",
    "- Lemmatizer\n",
    "- CountVectorizer\n",
    "    - stop_words='english'\n",
    "    - ngram_range=(1,1)\n",
    "- GridSearch\n",
    "    - cv__max_features=3490\n",
    "    - mnb__alpha=1.05\n",
    "\n",
    "### Model 2: Random Forest\n",
    "\n",
    "- Lemmatizer\n",
    "- CountVectorizer\n",
    "    - stop_words='english'\n",
    "    - ngram_range=(1,1)\n",
    "- GridSearch\n",
    "    - tf__max_features=None\n",
    "    - rf__criterion='gini'\n",
    "    - rf__n_estimators=93\n",
    "    - rf__max_depth=8\n",
    "\n",
    "### Model 3: KNN\n",
    "\n",
    "- Lemmatizer\n",
    "- CountVectorizer\n",
    "    - stop_words='english'\n",
    "    - ngram_range=(1,1)\n",
    "- GridSearch\n",
    "    - cv__max_features=None\n",
    "    - rf__criterion='gini'\n",
    "    - rf__n_estimators=93\n",
    "    - rf__max_depth=8\n",
    "\n",
    "### Model 4: Logistic Regression\n",
    "\n",
    "- Lemmatizer\n",
    "- CountVectorizer\n",
    "    - stop_words='english'\n",
    "    - ngram_range=(1,1)\n",
    "- GridSearch\n",
    "    - cv__max_features=1700\n",
    "    - lr__C=1.44\n",
    "    \n",
    "The respective scores are shown below as well:\n",
    "\n",
    "|Model|Test-accuracy|ROC AUC score|\n",
    "|---|---|---|\n",
    "|Multinomial Naive-Bayes|0.91|0.97|\n",
    "|Random Forest|0.81|0.97|\n",
    "|KNN|0.67|0.71|\n",
    "|Logistic Regression|0.87|0.93|\n",
    "\n",
    "The best performing model is model 1, the Multinomial Naive-Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue to Notebook 5: Model Testing, Data Interpretation, Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
