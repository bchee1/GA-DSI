{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Natural Language Processing and Classification\n",
    "\n",
    "Benjamin Chee, DSI-SG-17\n",
    "\n",
    "Classifying posts from r/xboxone and r/PS5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Pre-processing\n",
    "\n",
    "This notebook contains code used to:\n",
    "- tokenise\n",
    "- stem/lemmatise and compare between them\n",
    "\n",
    "Contents:\n",
    "- Pre-processing\n",
    "- Tokenizing Titles and Posts\n",
    "- Stemming Tokens\n",
    "- Lemmatizing Tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise date time\n",
    "date_run = datetime.datetime.now()\n",
    "date= date_run.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading output from notebook 1\n",
    "df=pd.read_csv('./csv/df_final_2020-10-02.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First treatment, set up regex, then remove undetected white space, ampersands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to greedily include words, slash characters for urls, apostrophes\n",
    "rt = RegexpTokenizer(r\"[\\w/\\']+\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace ampersands and spaces which wont be cauglt\n",
    "df.comb.replace('&amp;','&',inplace=True)\n",
    "df.comb.replace('#x200B;',' ',inplace=True) # zero width space\n",
    "df.comb.replace('nbsp;',' ',inplace=True) #non breaking space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenising each post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_tokens = []  # empty token list\n",
    "\n",
    "for i in range(len(df.comb)):\n",
    "    loop_tokens = rt.tokenize(df.comb.at[i].lower())\n",
    "    for j, token in enumerate(loop_tokens):\n",
    "        if re.match(r\"\\d+[\\w]*\", token):\n",
    "            loop_tokens[j] = ''\n",
    "        if re.match(r\"//[\\w]*\", token):\n",
    "            loop_tokens[j] = ''\n",
    "        if ('PS5' in token)|('xboxone' in token)|('http' in token):\n",
    "            loop_tokens[j] = ''\n",
    "    comb_tokens.append(loop_tokens)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem vs lemmatise\n",
    "\n",
    "We will stem and lemmatise tokens to see how they measure up in a rough model\n",
    "Their effectiveness will be evaluated during the first cut of model selection (next notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise Porter Stemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tech',\n",
       " 'weekli',\n",
       " 'xbox',\n",
       " 'one',\n",
       " 'tech',\n",
       " 'support',\n",
       " 'thi',\n",
       " 'is',\n",
       " 'the',\n",
       " 'thread']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# posts tokenized stemmed\n",
    "posts_st = [] \n",
    "\n",
    "for post in comb_tokens:\n",
    "    post_st = [] # empty post stems\n",
    "    for word in post:\n",
    "        #print(word)\n",
    "        word_st = ps.stem(word) # get stem of word\n",
    "        post_st.append(word_st) # add to post list\n",
    "    posts_st.append(post_st)  # add post list to stem matrix\n",
    "    \n",
    "posts_st[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already we see some of the common errors, such as 'thi' and 'weekli' for 'this' and 'weekly' respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format tokenized stems for vectorizer: list of strings\n",
    "posts_st_list = []\n",
    "\n",
    "for post in posts_st:\n",
    "    posts_st_list.append(' '.join(post))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will lemmatise the same tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tech',\n",
       " 'weekly',\n",
       " 'xbox',\n",
       " 'one',\n",
       " 'tech',\n",
       " 'support',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'thread']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_lm = []\n",
    "\n",
    "for post in comb_tokens:\n",
    "    post_st = [] # empty post stems\n",
    "    for word in post:\n",
    "        #print(word)\n",
    "        word_st = lm.lemmatize(word) # get lemmatized word\n",
    "        post_st.append(word_st) # add to post list\n",
    "    posts_lm.append(post_st)  # add post list to lemma matrix\n",
    "    \n",
    "posts_lm[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output looks a lot better for the lemmatised output, without any of the errors seen earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lemmatised list for each post\n",
    "posts_lm_list = []\n",
    "\n",
    "for post in posts_lm:\n",
    "    posts_lm_list.append(' '.join(post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"tech weekly xbox one tech support this is the thread where subscriber should bring their xbox support issue the collective experience of the xbox community is one of the most powerful tool to help you fix any gaming issue and we've been seeing some awesome response we love to see gamers helping gamers there will also be xbox support team member who will be helping moderate and provide solution and can be recognized by their official support flair we ll try to provide support right here in the thread but won't be able to respond to every single question we might redirect you to support xbox com   xbox com to contact one of our support team or send you a private message if that s the best way to help the xbox support team member won't respond to request for help with third party product or situation that would violate the term of use community standard or void a product warranty let u know what you need help with we re here to help you with xbox service game hardware social feature and more thank you for being part of the xbox community\",\n",
       " \"gta iv one of my fav game ever nearly a locked  on series x back compat my pc ha a hard time doing this cause it's such a shit port let's go microsoft keep the good news coming\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_lm_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_st</th>\n",
       "      <th>post_lm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech weekli xbox one tech support thi is the t...</td>\n",
       "      <td>tech weekly xbox one tech support this is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gta iv one of my fav game ever nearli a lock  ...</td>\n",
       "      <td>gta iv one of my fav game ever nearly a locked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>more seri x load time comparison</td>\n",
       "      <td>more series x load time comparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digit foundri xbox seri x backward compat test...</td>\n",
       "      <td>digital foundry xbox series x backwards compat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you rememb when thi pictur blew our mind</td>\n",
       "      <td>do you remember when this picture blew our mind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             post_st  \\\n",
       "0  tech weekli xbox one tech support thi is the t...   \n",
       "1  gta iv one of my fav game ever nearli a lock  ...   \n",
       "2                   more seri x load time comparison   \n",
       "3  digit foundri xbox seri x backward compat test...   \n",
       "4        do you rememb when thi pictur blew our mind   \n",
       "\n",
       "                                             post_lm  \n",
       "0  tech weekly xbox one tech support this is the ...  \n",
       "1  gta iv one of my fav game ever nearly a locked...  \n",
       "2                 more series x load time comparison  \n",
       "3  digital foundry xbox series x backwards compat...  \n",
       "4    do you remember when this picture blew our mind  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add all tokens into a single data frame\n",
    "df_pre = pd.DataFrame(data=[posts_st_list, posts_lm_list], index=['post_st','post_lm'])\n",
    "df_pre = df_pre.T\n",
    "df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1363"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " # remove nulls to continue\n",
    "df_pre.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding our target variable, checkpoint save\n",
    "\n",
    "df_pre['from_ps5'] = df['from_ps5']\n",
    "df_pre.to_csv(f'./csv/df_pre_{date}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue to Notebook 3: Model Selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
