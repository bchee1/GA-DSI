{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Notebook 3: Testing Models and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will evaluate the various models which we have trained in Notebook 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "df_test = pd.read_csv('./balanced-one-partition/pneumo_dataset_ITI_rev_clean.tsv' , sep=\"\\t\")\n",
    "y, x, in_channel = 524, 524, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the fourth GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from pneumo_data_generator import DataGenerator\n",
    "\n",
    "data_filter  = df_test['Projection']=='PA'\n",
    "data_filter &= df_test['Partition']=='te'\n",
    "df_pneumo_2d_test=df_test[data_filter]\n",
    "data_generator_test = DataGenerator( df_pneumo_2d_test[data_filter ], y, x, in_channel, batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2378, 39)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pneumo_2d_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data_generator_test.__getitem__(5)\n",
    "img=np.squeeze(data[0], axis=(0,))\n",
    "img=np.squeeze(img, axis=(2,))*255 #denorm after dropping index arrays\n",
    "#np.squeeze(data[0], axis=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_treated = Image.fromarray(img)\n",
    "ig_treated.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CNN model\n",
    "CNNmodel= load_model('./models/modelCNN-train.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2378/2378 [==============================] - 371s 156ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_CNN = CNNmodel.predict(data_generator_test,steps = len(data_generator_test),verbose=1) #calls getitem\n",
    "#predict = np.argmax(predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21354504, 0.786455  ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predict_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20709012], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# VGG model\n",
    "vggmodel= load_model('./models/vggmodel-train.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2378/2378 [==============================] - 68s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_vgg = vggmodel.predict_generator(data_generator_test,steps = len(data_generator_test),verbose=1,\n",
    "                               workers=1, use_multiprocessing=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20379415, 0.7962058 ],\n",
       "       [0.20379415, 0.7962058 ],\n",
       "       [0.20379415, 0.7962058 ],\n",
       "       ...,\n",
       "       [0.20379418, 0.7962058 ],\n",
       "       [0.20379418, 0.7962058 ],\n",
       "       [0.20379412, 0.7962058 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resnet model\n",
    "resnetmodel= load_model('./models/resnetmodel-train.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2378/2378 [==============================] - 94s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_resnet = resnetmodel.predict(data_generator_test,steps = len(data_generator_test),verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19495799, 0.805042  ],\n",
       "       [0.19495799, 0.805042  ],\n",
       "       [0.19495799, 0.805042  ],\n",
       "       ...,\n",
       "       [0.19495799, 0.805042  ],\n",
       "       [0.19495799, 0.805042  ],\n",
       "       [0.19495799, 0.805042  ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-657ac04933fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#inception model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minceptionmodel\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./models/inceptionmodel-train.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "#inception model\n",
    "inceptionmodel= load_model('./models/inceptionmodel-train.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2378/2378 [==============================] - 174s 73ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_inception = inceptionmodel.predict(data_generator_test,steps = len(data_generator_test),verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19546415, 0.80453587],\n",
       "       [0.19546415, 0.80453587],\n",
       "       [0.19546415, 0.80453587],\n",
       "       ...,\n",
       "       [0.19546415, 0.80453587],\n",
       "       [0.19546415, 0.80453587],\n",
       "       [0.19546415, 0.80453587]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, all 4 models are pretty close to each other in terms of their accuracy, with little to differentiate between them. This brings us to the next criterion of the models, which is the number of parameters, and the amount taken to train each of the models. They are summarised in the table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Model\t|Train Score|Validation Score|Test Score|No. of Params| Training Time|\n",
    "|---\t|---\t|---|---|---|---|\n",
    "|CNN|0.8044|0.8111|0.7930|60,940,898|17min|\n",
    "|VGG16|0.8044|0.8111|0.7962|15,238,018|32 min|\n",
    "|ResNet50|0.8041|0.8111|0.8050|25,678,786|47 min|\n",
    "|InceptionNet|0.8042 |0.8111|0.8045|55,221,090|1h|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While ResNet50 and InceptionNet were marginally better at predicting the test scores, the sheer amount of time they needed to train prohibits them to be used on any but the most powerful computing devices for computation. \n",
    "\n",
    "On the other hand, prediction remained relatively computationally inexpensive, with each sample run of 2000+ images in the test set being cleared in less than 3 min. Thus, ResNet50 and InceptionNet may still have some value locally on machines in hospitals, which may make them useful for diagnosis. \n",
    "\n",
    "Another factor is the size of the model .hdf5 file as well, which are on the order of megabytes. These may make it difficult for hospitals to retrieve, or store these models locally, especially since there will be models for many other diseases who are using vision machine learning for diagnosis as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "These models can be further extended to Computed Tomography scans, which are X-ray images done in 3-dimensions. A relatively simple 3layer model was reported to be able to achieve 83% accuracy for a similar pneumonia study:\n",
    "https://keras.io/examples/vision/3D_image_classification/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
