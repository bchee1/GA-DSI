{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Natural Language Processing and Classification\n",
    "\n",
    "Benjamin Chee, DSI-SG-17\n",
    "\n",
    "Classifying posts from r/xboxone and r/PS5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Model Selection\n",
    "\n",
    "This notebook contains code used to classify with models using our prepared data.\n",
    "\n",
    "The following were used:\n",
    "- Multinomial Naive Bayes\n",
    "- K-Nearest Neighbors\n",
    "- Logistic Regression Classifier\n",
    "- Random Forest\n",
    "\n",
    "2 Vectorisation methods were used:\n",
    "- CountVectorizer\n",
    "- TF-IDF\n",
    "\n",
    "GridSearch was then used to optimise each model\n",
    "\n",
    "Contents:\n",
    "- GridSearch - CountVectorizer\n",
    "- GridSearch - TF-IDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# general scikitlearn imports\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#NLP\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise date time\n",
    "date_run = datetime.datetime.now()\n",
    "date= date_run.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reading output from notebook 1\n",
    "df_pre=pd.read_csv('./csv/df_pre_2020-10-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1362"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pre[['post_st','post_lm']]\n",
    "y = df_pre['from_ps5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_st</th>\n",
       "      <th>post_lm</th>\n",
       "      <th>from_ps5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech weekli xbox one tech support thi is the t...</td>\n",
       "      <td>tech weekly xbox one tech support this is the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gta iv one of my fav game ever nearli a lock  ...</td>\n",
       "      <td>gta iv one of my fav game ever nearly a locked...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>more seri x load time comparison</td>\n",
       "      <td>more series x load time comparison</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digit foundri xbox seri x backward compat test...</td>\n",
       "      <td>digital foundry xbox series x backwards compat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you rememb when thi pictur blew our mind</td>\n",
       "      <td>do you remember when this picture blew our mind</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>an entir game gener ha gone and we have not ha...</td>\n",
       "      <td>an entire gaming generation ha gone and we hav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>did anyon els notic the live wallpap on the se...</td>\n",
       "      <td>did anyone else notice the live wallpaper on t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>year of play xbox ha brought me to thi point ...</td>\n",
       "      <td>year of playing xbox ha brought me to this po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xsx is the most quiet xbox ever i'll conclud t...</td>\n",
       "      <td>xsx is the most quiet xbox ever i'll conclude ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>each gamer score you get on oct   will convert...</td>\n",
       "      <td>each gamer score you get on oct   will convert...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xbox seri x hand on load time quick resum and ...</td>\n",
       "      <td>xbox series x hand on load time quick resume a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the seri x will have  of usabl space the rest ...</td>\n",
       "      <td>the series x will have  of usable space the re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a week with the xbox seri x load time game per...</td>\n",
       "      <td>a week with the xbox series x load time game p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lock  on gta iv final seri x</td>\n",
       "      <td>locked  on gta iv finally series x</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>so some fan decid to make thi awesom xgp trail...</td>\n",
       "      <td>so some fan decided to make this awesome xgp t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xbox seri x preview load time compar with some...</td>\n",
       "      <td>xbox series x preview load time compared with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>remind xbox head phil spencer ha alreadi addre...</td>\n",
       "      <td>reminder xbox head phil spencer ha already add...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>xbox' hall of fame reward player for gamerscor...</td>\n",
       "      <td>xbox's hall of fame reward player for gamersco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>throwback to the requir point need to download...</td>\n",
       "      <td>throwback to the required point needed to down...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xbox seri x hand on preview less wait more gam...</td>\n",
       "      <td>xbox series x hand on preview le waiting more ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>the xbox seri s is look realli nice</td>\n",
       "      <td>the xbox series s is looking really nice</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bc mode on seri x digit foundri teaser   com/d...</td>\n",
       "      <td>bc mode on series x digital foundry teaser   c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>if the rumor of xbox want sega are true we cou...</td>\n",
       "      <td>if the rumor of xbox wanting sega are true we ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mega thread xbox seri x hand on video digit fo...</td>\n",
       "      <td>mega thread xbox series x hand on video digita...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>xbox seri x hand on the big back compat dive b...</td>\n",
       "      <td>xbox series x hand on the big back compat dive...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>df analysi</td>\n",
       "      <td>df analysis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>deal xbox live deal with gold and spotlight sa...</td>\n",
       "      <td>deal xbox live deal with gold and spotlight sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ah ye stonk</td>\n",
       "      <td>ah yes stonks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>design lab costum control arriv</td>\n",
       "      <td>design lab costume controller arrived</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>the divis  ha such a uniqu atmospher don't for...</td>\n",
       "      <td>the division  ha such a unique atmosphere don'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              post_st  \\\n",
       "0   tech weekli xbox one tech support thi is the t...   \n",
       "1   gta iv one of my fav game ever nearli a lock  ...   \n",
       "2                    more seri x load time comparison   \n",
       "3   digit foundri xbox seri x backward compat test...   \n",
       "4         do you rememb when thi pictur blew our mind   \n",
       "5   an entir game gener ha gone and we have not ha...   \n",
       "6   did anyon els notic the live wallpap on the se...   \n",
       "7    year of play xbox ha brought me to thi point ...   \n",
       "8   xsx is the most quiet xbox ever i'll conclud t...   \n",
       "9   each gamer score you get on oct   will convert...   \n",
       "10  xbox seri x hand on load time quick resum and ...   \n",
       "11  the seri x will have  of usabl space the rest ...   \n",
       "12  a week with the xbox seri x load time game per...   \n",
       "13                       lock  on gta iv final seri x   \n",
       "14  so some fan decid to make thi awesom xgp trail...   \n",
       "15  xbox seri x preview load time compar with some...   \n",
       "16  remind xbox head phil spencer ha alreadi addre...   \n",
       "17  xbox' hall of fame reward player for gamerscor...   \n",
       "18  throwback to the requir point need to download...   \n",
       "19  xbox seri x hand on preview less wait more gam...   \n",
       "20                the xbox seri s is look realli nice   \n",
       "21  bc mode on seri x digit foundri teaser   com/d...   \n",
       "22  if the rumor of xbox want sega are true we cou...   \n",
       "23  mega thread xbox seri x hand on video digit fo...   \n",
       "24  xbox seri x hand on the big back compat dive b...   \n",
       "25                                         df analysi   \n",
       "26  deal xbox live deal with gold and spotlight sa...   \n",
       "27                                        ah ye stonk   \n",
       "28                    design lab costum control arriv   \n",
       "29  the divis  ha such a uniqu atmospher don't for...   \n",
       "\n",
       "                                              post_lm  from_ps5  \n",
       "0   tech weekly xbox one tech support this is the ...         0  \n",
       "1   gta iv one of my fav game ever nearly a locked...         0  \n",
       "2                  more series x load time comparison         0  \n",
       "3   digital foundry xbox series x backwards compat...         0  \n",
       "4     do you remember when this picture blew our mind         0  \n",
       "5   an entire gaming generation ha gone and we hav...         0  \n",
       "6   did anyone else notice the live wallpaper on t...         0  \n",
       "7    year of playing xbox ha brought me to this po...         0  \n",
       "8   xsx is the most quiet xbox ever i'll conclude ...         0  \n",
       "9   each gamer score you get on oct   will convert...         0  \n",
       "10  xbox series x hand on load time quick resume a...         0  \n",
       "11  the series x will have  of usable space the re...         0  \n",
       "12  a week with the xbox series x load time game p...         0  \n",
       "13                 locked  on gta iv finally series x         0  \n",
       "14  so some fan decided to make this awesome xgp t...         0  \n",
       "15  xbox series x preview load time compared with ...         0  \n",
       "16  reminder xbox head phil spencer ha already add...         0  \n",
       "17  xbox's hall of fame reward player for gamersco...         0  \n",
       "18  throwback to the required point needed to down...         0  \n",
       "19  xbox series x hand on preview le waiting more ...         0  \n",
       "20           the xbox series s is looking really nice         0  \n",
       "21  bc mode on series x digital foundry teaser   c...         0  \n",
       "22  if the rumor of xbox wanting sega are true we ...         0  \n",
       "23  mega thread xbox series x hand on video digita...         0  \n",
       "24  xbox series x hand on the big back compat dive...         0  \n",
       "25                                        df analysis         0  \n",
       "26  deal xbox live deal with gold and spotlight sa...         0  \n",
       "27                                      ah yes stonks         0  \n",
       "28              design lab costume controller arrived         0  \n",
       "29  the division  ha such a unique atmosphere don'...         0  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_st    0\n",
       "post_lm    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1021"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1021"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "The GridSearchCV tool allows us to program multiple hyperparameters across our models. It will generate a model with each combination of our desired hyperparameters, and optimize the highest-scoring result.\n",
    "\n",
    "We will run a single model for each of the following 6 classifiers:\n",
    "\n",
    "Multinomial Naive Bayes\n",
    "K-Nearest Neighbors\n",
    "Logistic Regression\n",
    "Random Forest\n",
    "AdaBoost (adaptive boost)\n",
    "Gradient Boost\n",
    "We will run two GridSearches to benchmark these models for two feature extraction techniques: CountVectorizer and TfidfVectorizer. We can use the accuracy of the results to narrow our model selection to the most effective approaches.\n",
    "\n",
    "As these models execute, the results will be displayed, then stored into a DataFrame for final comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of pipeline steps for each model combo\n",
    "steps_list_gr_cv = [ \n",
    "    [('cv',CountVectorizer()),('multi_nb',MultinomialNB())],\n",
    "    [('cv',CountVectorizer()),('scaler',StandardScaler(with_mean=False)),('knn',KNeighborsClassifier())], \n",
    "    [('cv',CountVectorizer()),('scaler',StandardScaler(with_mean=False)),('logreg',LogisticRegression())],\n",
    "    [('cv',CountVectorizer()),('rf',RandomForestClassifier())]\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_titles = ['multi_nb','knn','logreg','rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params_cv = [\n",
    "    {'cv__stop_words':['english'], 'cv__ngram_range':[(1,1),(1,2)]},\n",
    "    {'cv__stop_words':['english'], 'cv__ngram_range':[(1,1),(1,2)]},\n",
    "    {'cv__stop_words':['english'], 'cv__ngram_range':[(1,1),(1,2)]},\n",
    "    {'cv__stop_words':['english'], 'cv__ngram_range':[(1,1),(1,2)]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, best_params, train_accuracy, test_accuracy, tn, fp, fn, tp]\n",
       "Index: []"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate results DataFrame\n",
    "grid_results = pd.DataFrame(columns=['model','best_params','train_accuracy','test_accuracy','tn','fp','fn','tp'])\n",
    "grid_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre_post = X_train['post_lm']\n",
    "X_test_pre_post = X_test['post_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████                                                               | 1/4 [00:00<00:01,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  multi_nb\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}\n",
      "0.9755142017629774 \n",
      "\n",
      "0.9149560117302052 \n",
      "\n",
      "True Positives: 196\n",
      "True Positives: 16\n",
      "True Positives: 13\n",
      "True Positives: 116 \n",
      "\n",
      "Model:  knn\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}\n",
      "0.7267384916748286 \n",
      "\n",
      "0.6686217008797654 \n",
      "\n",
      "True Positives: 209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 2/4 [00:01<00:01,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Positives: 3\n",
      "True Positives: 110\n",
      "True Positives: 19 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [00:02<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  logreg\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}\n",
      "1.0 \n",
      "\n",
      "0.8269794721407625 \n",
      "\n",
      "True Positives: 199\n",
      "True Positives: 13\n",
      "True Positives: 46\n",
      "True Positives: 83 \n",
      "\n",
      "Model:  rf\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': 'english'}\n",
      "1.0 \n",
      "\n",
      "0.906158357771261 \n",
      "\n",
      "True Positives: 209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Positives: 3\n",
      "True Positives: 29\n",
      "True Positives: 100 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(steps_list_gr_cv))):           # timed loop through index of number of steps\n",
    "    pipe = Pipeline(steps=steps_list_gr_cv[i])         # configure pipeline for each model\n",
    "    grid = GridSearchCV(pipe, pipe_params_cv[i], cv=3) # fit GridSearchCV to model and model's params\n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    grid.fit(X_train_pre_post, y_train)\n",
    "    \n",
    "    print('Model: ',steps_titles[i])\n",
    "    model_results['model'] = steps_titles[i]\n",
    "\n",
    "    print('Best Params: ', grid.best_params_)\n",
    "    model_results['best_params'] = grid.best_params_\n",
    "\n",
    "    print(grid.score(X_train_pre_post, y_train), '\\n')\n",
    "    model_results['train_accuracy'] = grid.score(X_train_pre_post, y_train)\n",
    "    \n",
    "    print(grid.score(X_test_pre_post, y_test), '\\n')\n",
    "    model_results['test_accuracy'] = grid.score(X_test_pre_post, y_test)\n",
    "\n",
    "    # Display the confusion matrix results showing true/false positive/negative\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_pre_post)).ravel() \n",
    "    print(f'True Positives: {tn}')\n",
    "    model_results['tn'] = tn\n",
    "\n",
    "    print(f'True Positives: {fp}')\n",
    "    model_results['fp'] = fp\n",
    "\n",
    "    print(f'True Positives: {fn}')\n",
    "    model_results['fn'] = fn\n",
    "\n",
    "    print(f'True Positives: {tp}', '\\n')\n",
    "    model_results['tp'] = tp\n",
    "    \n",
    "    grid_results = grid_results.append(model_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_cv = grid_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>0.975514</td>\n",
       "      <td>0.914956</td>\n",
       "      <td>196</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906158</td>\n",
       "      <td>209</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826979</td>\n",
       "      <td>199</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>0.726738</td>\n",
       "      <td>0.668622</td>\n",
       "      <td>209</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                                        best_params  \\\n",
       "0  multi_nb  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "3        rf  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "2    logreg  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "1       knn  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "\n",
       "   train_accuracy  test_accuracy   tn  fp   fn   tp  \n",
       "0        0.975514       0.914956  196  16   13  116  \n",
       "3        1.000000       0.906158  209   3   29  100  \n",
       "2        1.000000       0.826979  199  13   46   83  \n",
       "1        0.726738       0.668622  209   3  110   19  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.sort_values('test_accuracy',ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_list_gr_tf = [ # list of pipeline steps for each model combo\n",
    "    [('tf',TfidfVectorizer()),('multi_nb',MultinomialNB())],\n",
    "    [('tf',TfidfVectorizer()),('scaler',StandardScaler(with_mean=False)),('knn',KNeighborsClassifier())], \n",
    "    [('tf',TfidfVectorizer()),('scaler',StandardScaler(with_mean=False)),('logreg',LogisticRegression())],\n",
    "    [('tf',TfidfVectorizer()),('rf',RandomForestClassifier())]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_titles = ['multi_nb','knn','logreg','rf']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params_tf = [\n",
    "    {'tf__stop_words':['english'], 'tf__ngram_range':[(1,1),(1,2)]},\n",
    "    {'tf__stop_words':['english'], 'tf__ngram_range':[(1,1),(1,2)]},\n",
    "    {'tf__stop_words':['english'], 'tf__ngram_range':[(1,1),(1,2)]},\n",
    "    {'tf__stop_words':['english'], 'tf__ngram_range':[(1,1),(1,2)]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, best_params, train_accuracy, test_accuracy, tn, fp, fn, tp]\n",
       "Index: []"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate results DataFrame\n",
    "grid_results = pd.DataFrame(columns=['model','best_params','train_accuracy','test_accuracy','tn','fp','fn','tp'])\n",
    "grid_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre_post = X_train['post_lm']\n",
    "X_test_pre_post = X_test['post_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████                                                               | 1/4 [00:00<00:01,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  multi_nb\n",
      "Best Params:  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}\n",
      "0.9324191968658179 \n",
      "\n",
      "0.8211143695014663 \n",
      "\n",
      "True Positives: 211\n",
      "True Positives: 1\n",
      "True Positives: 60\n",
      "True Positives: 69 \n",
      "\n",
      "Model:  knn\n",
      "Best Params:  {'tf__ngram_range': (1, 2), 'tf__stop_words': 'english'}\n",
      "0.6199804113614104 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 2/4 [00:01<00:01,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6217008797653959 \n",
      "\n",
      "True Positives: 212\n",
      "True Positives: 0\n",
      "True Positives: 129\n",
      "True Positives: 0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [00:02<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  logreg\n",
      "Best Params:  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}\n",
      "1.0 \n",
      "\n",
      "0.841642228739003 \n",
      "\n",
      "True Positives: 198\n",
      "True Positives: 14\n",
      "True Positives: 40\n",
      "True Positives: 89 \n",
      "\n",
      "Model:  rf\n",
      "Best Params:  {'tf__ngram_range': (1, 1), 'tf__stop_words': 'english'}\n",
      "1.0 \n",
      "\n",
      "0.9178885630498533 \n",
      "\n",
      "True Positives: 211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Positives: 1\n",
      "True Positives: 27\n",
      "True Positives: 102 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(steps_list_gr_tf))):           # timed loop through index of number of steps\n",
    "    pipe = Pipeline(steps=steps_list_gr_tf[i])         # configure pipeline for each model\n",
    "    grid = GridSearchCV(pipe, pipe_params_tf[i], cv=3) # fit GridSearchCV to model and model's params\n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    grid.fit(X_train_pre_post, y_train)\n",
    "    \n",
    "    print('Model: ',steps_titles[i])\n",
    "    model_results['model'] = steps_titles[i]\n",
    "\n",
    "    print('Best Params: ', grid.best_params_)\n",
    "    model_results['best_params'] = grid.best_params_\n",
    "\n",
    "    print(grid.score(X_train_pre_post, y_train), '\\n')\n",
    "    model_results['train_accuracy'] = grid.score(X_train_pre_post, y_train)\n",
    "    \n",
    "    print(grid.score(X_test_pre_post, y_test), '\\n')\n",
    "    model_results['test_accuracy'] = grid.score(X_test_pre_post, y_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test_pre_post)).ravel()\n",
    "    print(f'True Positives: {tn}')\n",
    "    model_results['tn'] = tn\n",
    "\n",
    "    print(f'True Positives: {fp}')\n",
    "    model_results['fp'] = fp\n",
    "\n",
    "    print(f'True Positives: {fn}')\n",
    "    model_results['fn'] = fn\n",
    "\n",
    "    print(f'True Positives: {tp}', '\\n')\n",
    "    model_results['tp'] = tp\n",
    "\n",
    "    grid_results = grid_results.append(model_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_tf = grid_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917889</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841642</td>\n",
       "      <td>198</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': ...</td>\n",
       "      <td>0.932419</td>\n",
       "      <td>0.821114</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'tf__ngram_range': (1, 2), 'tf__stop_words': ...</td>\n",
       "      <td>0.619980</td>\n",
       "      <td>0.621701</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                                        best_params  \\\n",
       "3        rf  {'tf__ngram_range': (1, 1), 'tf__stop_words': ...   \n",
       "2    logreg  {'tf__ngram_range': (1, 1), 'tf__stop_words': ...   \n",
       "0  multi_nb  {'tf__ngram_range': (1, 1), 'tf__stop_words': ...   \n",
       "1       knn  {'tf__ngram_range': (1, 2), 'tf__stop_words': ...   \n",
       "\n",
       "   train_accuracy  test_accuracy   tn  fp   fn   tp  \n",
       "3        1.000000       0.917889  211   1   27  102  \n",
       "2        1.000000       0.841642  198  14   40   89  \n",
       "0        0.932419       0.821114  211   1   60   69  \n",
       "1        0.619980       0.621701  212   0  129    0  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.sort_values('test_accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results assessment\n",
    "Adding columns for the gap between train and set accuracy scores. This will tell us about the level of overfitting that may be present in each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The baseline accuracy is the likelihood of a post being from_ps5=1 based solely on the percentage of our dataset that is our target value. Here, we normalize our value counts to show a baseline accuracy of 62.0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.61998\n",
       "1    0.38002\n",
       "Name: from_ps5, dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing vs test train scroe to see generalisability\n",
    "grid_results_tf['tt_delta'] = grid_results_tf['train_accuracy'] - grid_results_tf['test_accuracy']\n",
    "grid_results_cv['tt_delta'] = grid_results_cv['train_accuracy'] - grid_results_cv['test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing vs baseline\n",
    "grid_results_tf['ba_delta'] = grid_results_tf['test_accuracy'] - y_train.value_counts(normalize=True)[1]\n",
    "grid_results_cv['ba_delta'] = grid_results_cv['test_accuracy'] - y_train.value_counts(normalize=True)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>tt_delta</th>\n",
       "      <th>ba_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>0.975514</td>\n",
       "      <td>0.914956</td>\n",
       "      <td>196</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>116</td>\n",
       "      <td>0.060558</td>\n",
       "      <td>0.534936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906158</td>\n",
       "      <td>209</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>100</td>\n",
       "      <td>0.093842</td>\n",
       "      <td>0.526139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826979</td>\n",
       "      <td>199</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>83</td>\n",
       "      <td>0.173021</td>\n",
       "      <td>0.446960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'cv__ngram_range': (1, 1), 'cv__stop_words': ...</td>\n",
       "      <td>0.726738</td>\n",
       "      <td>0.668622</td>\n",
       "      <td>209</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>19</td>\n",
       "      <td>0.058117</td>\n",
       "      <td>0.288602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                                        best_params  \\\n",
       "0  multi_nb  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "3        rf  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "2    logreg  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "1       knn  {'cv__ngram_range': (1, 1), 'cv__stop_words': ...   \n",
       "\n",
       "   train_accuracy  test_accuracy   tn  fp   fn   tp  tt_delta  ba_delta  \n",
       "0        0.975514       0.914956  196  16   13  116  0.060558  0.534936  \n",
       "3        1.000000       0.906158  209   3   29  100  0.093842  0.526139  \n",
       "2        1.000000       0.826979  199  13   46   83  0.173021  0.446960  \n",
       "1        0.726738       0.668622  209   3  110   19  0.058117  0.288602  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_cv.sort_values('test_accuracy',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>tt_delta</th>\n",
       "      <th>ba_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917889</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>102</td>\n",
       "      <td>0.082111</td>\n",
       "      <td>0.537869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841642</td>\n",
       "      <td>198</td>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>89</td>\n",
       "      <td>0.158358</td>\n",
       "      <td>0.461623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_nb</td>\n",
       "      <td>{'tf__ngram_range': (1, 1), 'tf__stop_words': ...</td>\n",
       "      <td>0.932419</td>\n",
       "      <td>0.821114</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>0.111305</td>\n",
       "      <td>0.441095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>{'tf__ngram_range': (1, 2), 'tf__stop_words': ...</td>\n",
       "      <td>0.619980</td>\n",
       "      <td>0.621701</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.001720</td>\n",
       "      <td>0.241681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                                        best_params  \\\n",
       "3        rf  {'tf__ngram_range': (1, 1), 'tf__stop_words': ...   \n",
       "2    logreg  {'tf__ngram_range': (1, 1), 'tf__stop_words': ...   \n",
       "0  multi_nb  {'tf__ngram_range': (1, 1), 'tf__stop_words': ...   \n",
       "1       knn  {'tf__ngram_range': (1, 2), 'tf__stop_words': ...   \n",
       "\n",
       "   train_accuracy  test_accuracy   tn  fp   fn   tp  tt_delta  ba_delta  \n",
       "3        1.000000       0.917889  211   1   27  102  0.082111  0.537869  \n",
       "2        1.000000       0.841642  198  14   40   89  0.158358  0.461623  \n",
       "0        0.932419       0.821114  211   1   60   69  0.111305  0.441095  \n",
       "1        0.619980       0.621701  212   0  129    0 -0.001720  0.241681  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_tf.sort_values('test_accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at model types, we can see that the CountVectorized Multinomial Naive-Bayes and Random Forest performed best on an initial run. We will select these two, as well as the RandomForest model, which was requested by the project requirements, and GradientBoost Decision Tree to enhance modeling accuracy. We will continue to optimize each of these models.\n",
    "\n",
    "Model Selections:\n",
    "\n",
    "1. Lemmatized CountVectorizer Multinomial Naive-Bayes\n",
    "\n",
    "    - cv__ngram_range=(1,1)\n",
    "\n",
    "    - cv__stop_words='english'\n",
    "\n",
    "\n",
    "2. Lemmatized TF-IDF Scaled Random Forest\n",
    "\n",
    "    - tf__ngram_range=(1,1)\n",
    "\n",
    "    - tf__stop_words='english'\n",
    "\n",
    "\n",
    "3. Lemmatized CountVectorizer K nearest neighbours\n",
    "\n",
    "    - cv__ngram_range=(1,1)\n",
    "\n",
    "    - cv__stop_words='english'\n",
    "\n",
    "\n",
    "4. Lemmatized CountVectorizer Logistic Regression\n",
    "\n",
    "    - cv__ngram_range=(1,1)\n",
    "\n",
    "    - cv__stop_words='english'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue to Notebook 4: Model Optimisation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
